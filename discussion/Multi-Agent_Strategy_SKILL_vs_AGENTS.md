# ë©€í‹°-ì—ì´ì „íŠ¸ ì „ëµ: SKILL.md vs AGENTS.md

**ì‘ì„±ì¼**: 2025-10-23
**ëª©ì **: Claude Codeì™€ OpenAI Codex ëª¨ë‘ ì§€ì›í•˜ê¸° ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ íŒŒì¼ ì „ëµ ìˆ˜ë¦½

---

## ğŸ¤” ë¬¸ì œ ì •ì˜

### í˜„ì¬ ìƒí™©
- **ScholaRAG**: `SKILL.md` (Codex ì „ìš©, 40 lines) + `CLAUDE.md` (Claude ì „ìš©, 100 lines)
- **ScholaRAG-helper**: `AGENTS.md` (Codex ì „ìš©, 523 lines) + `CLAUDE.md` (Claude ì „ìš©, minimal)

### ì§ˆë¬¸ë“¤
1. **SKILL.mdëŠ” ë‹¤ë¥¸ ì—°êµ¬ìì—ê²Œë„ í•„ìš”í•œê°€?**
   - â†’ ë‹µ: **ì•„ë‹ˆìš”**, SKILL.mdëŠ” AI ì—ì´ì „íŠ¸(Claude/Codex)ê°€ ì½ëŠ” íŒŒì¼ì…ë‹ˆë‹¤
   - ì—°êµ¬ìëŠ” **ì›¹ì‚¬ì´íŠ¸ ë¬¸ì„œ**ë¥¼ ì½ìŠµë‹ˆë‹¤ (https://www.scholarag.com/guide)

2. **Codexì™€ Claude ëª¨ë‘ ì§€ì›í•˜ë ¤ë©´?**
   - â†’ ë‹µ: **SKILL.md (Claude) + AGENTS.md (Codex) ë³‘í–‰ ìœ ì§€**
   - í•˜ì§€ë§Œ ë‚´ìš© ì¤‘ë³µì„ ìµœì†Œí™”í•´ì•¼ í•¨

3. **ì¤‘ë³µ í´ë”(ResearcherRAG-helper 2) í•„ìš”í•œê°€?**
   - â†’ ë‹µ: **ì‚­ì œ ê¶Œì¥**
   - ë©”ì¸ì€ ScholaRAG-helper, ë°±ì—…ì€ .backupìœ¼ë¡œ ì¶©ë¶„

---

## ğŸ“‹ ì „ëµ 1: SKILL.md vs AGENTS.md ì—­í•  ë¶„ë‹´

### ê¸°ë³¸ ì›ì¹™: DRY (Don't Repeat Yourself)

**ë¬¸ì œ**: SKILL.mdì™€ AGENTS.mdê°€ ê°™ì€ ì •ë³´ë¥¼ ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ì¤‘ë³µ ì €ì¥
**í•´ê²°**: ì—­í• ì„ ëª…í™•íˆ ë¶„ë¦¬í•˜ê³ , ê³µí†µ ì •ë³´ëŠ” í•œ ê³³ì—ë§Œ ì €ì¥

---

### ì—­í•  ë¶„ë‹´ Matrix

| íŒŒì¼ | ëŒ€ìƒ ì—ì´ì „íŠ¸ | ì£¼ìš” ì—­í•  | í¬í•¨ ë‚´ìš© | ë°°ì œ ë‚´ìš© |
|------|--------------|----------|----------|----------|
| **SKILL.md** | Claude Code | Progressive disclosure, Stage-aware workflow | - Quick Start<br/>- Stage ë§í¬ (skills/*.md)<br/>- Critical branching points<br/>- Reference links | - ìƒì„¸ ì„¤ëª…<br/>- ê¸´ ì˜ˆì‹œ ì½”ë“œ<br/>- Troubleshooting (ë³„ë„ íŒŒì¼)<br/>- ìŠ¤í¬ë¦½íŠ¸ (ì‹¤í–‰ íŒŒì¼ë¡œ ë¶„ë¦¬) |
| **AGENTS.md** | OpenAI Codex, GPT-5-Codex | Task-based commands, Executable workflows | - Bash ëª…ë ¹ì–´ ì²´ì¸<br/>- Common workflows<br/>- Error recovery procedures<br/>- Validation checklists | - ê¸´ ê°œë… ì„¤ëª…<br/>- Architecture ì´ë¡ <br/>- ì—°êµ¬ ë°©ë²•ë¡  ì„¤ëª…<br/>- Stage ëŒ€í™” íë¦„ |
| **CLAUDE.md** | Claude Code (legacy) | Backward compatibility | - ê¸°ì¡´ í”„ë¡œì íŠ¸ ì§€ì›<br/>- SKILL.mdë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸<br/>- Migration ê°€ì´ë“œ | - ìƒˆë¡œìš´ ê¸°ëŠ¥<br/>- ìƒì„¸ ë¬¸ì„œ (SKILL.mdì— ìœ„ì„) |

---

## ğŸ“Š ì „ëµ 2: ê³„ì¸µì  ì»¨í…ìŠ¤íŠ¸ ì‹œìŠ¤í…œ (3-Tier)

### Tier 1: ë£¨íŠ¸ ë ˆë²¨ (Universal Context)

**ëª©ì **: ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ì½ëŠ” ê³µí†µ ë©”íƒ€ë°ì´í„°

```
ScholaRAG/
â”œâ”€â”€ SKILL.md (400 lines max)
â”‚   â”œâ”€â”€ Metadata (name, description)
â”‚   â”œâ”€â”€ Quick Start (5 min setup)
â”‚   â”œâ”€â”€ 7-Stage overview (table only)
â”‚   â””â”€â”€ Links to skills/*.md
â”‚
â”œâ”€â”€ AGENTS.md (500 lines max)
â”‚   â”œâ”€â”€ Repository context
â”‚   â”œâ”€â”€ Task-based workflows
â”‚   â”œâ”€â”€ Bash command chains
â”‚   â””â”€â”€ Validation checklists
â”‚
â””â”€â”€ CLAUDE.md (50 lines)
    â”œâ”€â”€ "This is legacy, see SKILL.md"
    â”œâ”€â”€ Quick migration guide
    â””â”€â”€ Link to skills/ folder
```

**í•µì‹¬**: ë£¨íŠ¸ íŒŒì¼ì€ **ì¸ë±ìŠ¤ ì—­í• **ë§Œ ìˆ˜í–‰, ìƒì„¸ ë‚´ìš©ì€ í•˜ìœ„ í´ë”ì— ìœ„ì„

---

### Tier 2: ë„ë©”ì¸ë³„ ìŠ¤í‚¬ í´ë” (Domain-Specific Skills)

**ëª©ì **: Claudeê°€ progressive disclosureë¡œ ë¡œë“œí•˜ëŠ” ìƒì„¸ ì»¨í…ìŠ¤íŠ¸

```
skills/
â”œâ”€â”€ stage1_research_setup.md (~300 lines)
â”œâ”€â”€ stage2_query_strategy.md (~300 lines)
â”œâ”€â”€ stage3_prisma_config.md (~400 lines)
â”œâ”€â”€ stage4_rag_design.md (~300 lines)
â”œâ”€â”€ stage5_execution.md (~250 lines)
â”œâ”€â”€ stage6_research_conversation.md (~500 lines)
â”œâ”€â”€ stage7_documentation.md (~200 lines)
â”œâ”€â”€ scenarios/
â”‚   â”œâ”€â”€ overview.md
â”‚   â”œâ”€â”€ hypothesis.md
â”‚   â”œâ”€â”€ statistics.md
â”‚   â””â”€â”€ ... (7 scenarios)
â”œâ”€â”€ reference/
â”‚   â”œâ”€â”€ api_reference.md
â”‚   â”œâ”€â”€ config_schema.md
â”‚   â”œâ”€â”€ project_type_decision_tree.md
â”‚   â””â”€â”€ troubleshooting.md
â””â”€â”€ example_conversations/
    â”œâ”€â”€ stage1_example.md
    â”œâ”€â”€ stage6_overview_example.md
    â””â”€â”€ stage6_hypothesis_example.md
```

**íŠ¹ì§•**:
- Claudeë§Œ ì½ìŒ (CodexëŠ” AGENTS.mdì˜ bash ëª…ë ¹ì–´ ì„ í˜¸)
- On-demand loading (í•„ìš”í•  ë•Œë§Œ)
- 500-line limit per file

---

### Tier 3: ì‹¤í–‰ ê°€ëŠ¥í•œ ìœ í‹¸ë¦¬í‹° (Executable Scripts)

**ëª©ì **: ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ (ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ë¶ˆí•„ìš”)

```
scripts/utils/
â”œâ”€â”€ generate_prompt_metadata.py
â”œâ”€â”€ validate_config.py
â”œâ”€â”€ check_stage_completion.py
â””â”€â”€ sync_context.py
```

**íŠ¹ì§•**:
- SKILL.mdë‚˜ AGENTS.mdì—ì„œ ì°¸ì¡°ë§Œ í•¨ (ì „ì²´ ì½”ë“œ í¬í•¨ ì•ˆ í•¨)
- Claude/Codex ëª¨ë‘ `python scripts/utils/xxx.py` í˜•íƒœë¡œ ì‹¤í–‰
- ê²°ê³¼ë¥¼ íŒŒì‹±í•´ì„œ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •

---

## ğŸ”„ ì „ëµ 3: Codexì™€ Claudeì˜ ì›Œí¬í”Œë¡œìš° ì°¨ì´ ëŒ€ì‘

### Claude Code ì›Œí¬í”Œë¡œìš° (Conversation-First)

**íŠ¹ì§•**:
- ì—°êµ¬ìì™€ ëŒ€í™”í•˜ë©° Stageë³„ ì§„í–‰
- Progressive disclosure (ë‹¨ê³„ë³„ë¡œ skills/*.md ë¡œë“œ)
- Validation ìë™ ìˆ˜í–‰ (metadata ê¸°ë°˜)

**SKILL.md êµ¬ì¡°**:
```markdown
---
name: scholarag
description: PRISMA 2020 systematic review with RAG. Use when researcher needs automated paper retrieval, screening, or research conversation.
---

# Quick Start
[5-minute setup guide]

# 7-Stage Overview
| Stage | Name | Read This | Duration |
|-------|------|-----------|----------|
| 1 | Research Setup | [skills/stage1_research_setup.md](skills/stage1_research_setup.md) | 15-20 min |
| ... | ... | ... | ... |

# Critical Branching Points
- **project_type**: knowledge_repository (50%) vs systematic_review (90%)
- **Stage 6**: 7 scenarios available

# Error Recovery
See [skills/error_recovery.md](skills/error_recovery.md)
```

**í† í° íš¨ìœ¨**:
- SKILL.md: ~400 lines (ë¡œë“œ 1íšŒ)
- Current stage file: ~300 lines (ë‹¨ê³„ë³„ 1íšŒ)
- **Total per conversation**: ~700 lines (vs ê¸°ì¡´ 2,000 lines)

---

### OpenAI Codex ì›Œí¬í”Œë¡œìš° (Task-First)

**íŠ¹ì§•**:
- ì‚¬ìš©ìê°€ ëª…í™•í•œ Task ì œì‹œ (e.g., "Stage 3 ì™„ë£Œ", "PDF ë‹¤ìš´ë¡œë“œ")
- Bash ëª…ë ¹ì–´ ì²´ì¸ ì§ì ‘ ì‹¤í–‰
- Validationì€ ëª…ë ¹ì–´ ì¢…ë£Œ ì½”ë“œë¡œ íŒë‹¨

**AGENTS.md êµ¬ì¡°**:
```markdown
# AGENTS.md - ScholaRAG

## Task 1: Initialize New Project

**When**: User says "Start new systematic review"

**Steps**:
1. Check prerequisites
   ```bash
   python --version  # >= 3.9
   which git
   ```

2. Initialize project
   ```bash
   cd "/path/to/ScholaRAG"
   python scholarag_cli.py init \
     --name "Project-Name" \
     --question "Research question?" \
     --domain education
   ```

3. Validate creation
   ```bash
   ls projects/YYYY-MM-DD_Project-Name/config.yaml
   # Expected: File exists
   ```

4. Report to user:
   - âœ… Project created at: [path]
   - âœ… config.yaml verified
   - â¡ï¸ Next: Run Task 2 (Query Design)

---

## Task 2: Design and Test Query

**When**: User says "Design search query" or "Stage 2"

**Steps**:
[Similar bash-centric workflow]
```

**ì°¨ì´ì **:
| Aspect | Claude (SKILL.md) | Codex (AGENTS.md) |
|--------|-------------------|-------------------|
| ìŠ¤íƒ€ì¼ | Conversation turns, validation rules | Bash commands, exit codes |
| ì˜ˆì‹œ | "Ask user about project_type" | `python scholarag_cli.py init --name $NAME` |
| ì—ëŸ¬ ì²˜ë¦¬ | Metadata validation | `if [ $? -ne 0 ]; then ...` |
| ì§„í–‰ ìƒí™© | `.claude/context.json` | Git commits, file existence checks |

---

## ğŸ“ ì „ëµ 4: ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ì œì•ˆ

### ScholaRAG ë©”ì¸ ì €ì¥ì†Œ

```
ScholaRAG/
â”œâ”€â”€ SKILL.md (400 lines) â† Claude Agent Skills ë©”ì¸ íŒŒì¼
â”‚   â”œâ”€â”€ Metadata (name: "scholarag", description: ...)
â”‚   â”œâ”€â”€ Quick Start
â”‚   â”œâ”€â”€ 7-Stage table with links
â”‚   â””â”€â”€ Critical branching points
â”‚
â”œâ”€â”€ AGENTS.md (500 lines) â† Codex ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ Task 1: Initialize Project
â”‚   â”œâ”€â”€ Task 2: Design Query
â”‚   â”œâ”€â”€ Task 3: Run PRISMA Screening
â”‚   â”œâ”€â”€ ... (7 tasks = 7 stages)
â”‚   â””â”€â”€ Validation checklists
â”‚
â”œâ”€â”€ CLAUDE.md (50 lines) â† Legacy redirect
â”‚   â””â”€â”€ "See SKILL.md for Agent Skills framework"
â”‚
â”œâ”€â”€ skills/ (Claude ì „ìš©)
â”‚   â”œâ”€â”€ stage1_research_setup.md
â”‚   â”œâ”€â”€ stage2_query_strategy.md
â”‚   â”œâ”€â”€ ... (7 files)
â”‚   â”œâ”€â”€ error_recovery.md
â”‚   â”œâ”€â”€ scenarios/
â”‚   â”œâ”€â”€ reference/
â”‚   â””â”€â”€ example_conversations/
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ 01_fetch_papers.py
    â”œâ”€â”€ 02_deduplicate.py
    â”œâ”€â”€ ... (ì‹¤ì œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸)
    â””â”€â”€ utils/
        â”œâ”€â”€ generate_prompt_metadata.py
        â””â”€â”€ validate_config.py
```

### ScholaRAG-helper ë¬¸ì„œ ì €ì¥ì†Œ

```
ScholaRAG-helper/
â”œâ”€â”€ AGENTS.md (523 lines) â† Codex ì „ìš© (Next.js í”„ë¡œì íŠ¸)
â”‚   â”œâ”€â”€ Task 1: Content Updates
â”‚   â”œâ”€â”€ Task 2: Add New Guide Chapter
â”‚   â”œâ”€â”€ Task 3: Update Search
â”‚   â””â”€â”€ Task 4: Troubleshoot Vercel
â”‚
â”œâ”€â”€ CLAUDE.md (50 lines) â† Claude ì „ìš© (ìµœì†Œ)
â”‚   â”œâ”€â”€ "This is documentation website"
â”‚   â”œâ”€â”€ "For ScholaRAG code, see ../ScholaRAG/"
â”‚   â””â”€â”€ "Update guide pages in frontend/app/guide/"
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ CLAUDE.md (100 lines)
â”‚   â”‚   â”œâ”€â”€ "Next.js 15 project"
â”‚   â”‚   â”œâ”€â”€ "Update components/SearchBar.tsx when adding content"
â”‚   â”‚   â””â”€â”€ "Test with npm run dev before push"
â”‚   â”‚
â”‚   â””â”€â”€ AGENTS.md (200 lines)
â”‚       â”œâ”€â”€ Task 1: Add search index entry
â”‚       â”œâ”€â”€ Task 2: Update guide chapter
â”‚       â””â”€â”€ Task 3: Deploy to Vercel
â”‚
â””â”€â”€ discussion/
    â”œâ”€â”€ ScholaRAG_Refactoring_Plan.md â† ë°©ê¸ˆ ì´ë™í•œ íŒŒì¼
    â””â”€â”€ Multi-Agent_Strategy_SKILL_vs_AGENTS.md â† ì´ íŒŒì¼
```

---

## ğŸ¯ ì „ëµ 5: ë‚´ìš© ì¤‘ë³µ ìµœì†Œí™” ê·œì¹™

### ê·œì¹™ 1: Single Source of Truth (SSOT)

**ê° ì •ë³´ëŠ” í•œ ê³³ì—ë§Œ ì €ì¥**:

| ì •ë³´ ìœ í˜• | SSOT ìœ„ì¹˜ | ì°¸ì¡° ë°©ë²• |
|----------|-----------|----------|
| 7-Stage ê°œìš” | SKILL.md | AGENTS.mdì—ì„œ "See SKILL.md for stage overview" |
| project_type decision tree | skills/reference/project_type_decision_tree.md | SKILL.md, AGENTS.md ëª¨ë‘ ë§í¬ë§Œ |
| API ì—”ë“œí¬ì¸íŠ¸ | skills/reference/api_reference.md | ì§ì ‘ ë³µì‚¬ ê¸ˆì§€, ë§í¬ë§Œ |
| Bash ëª…ë ¹ì–´ | AGENTS.md | SKILL.mdì—ì„œ "Run via Codex: see AGENTS.md Task X" |
| ì—ëŸ¬ ë³µêµ¬ ì ˆì°¨ | skills/error_recovery.md | ì–‘ìª½ ëª¨ë‘ ë§í¬ |

### ê·œì¹™ 2: í˜•ì‹ë³„ ë¶„ë¦¬

**Claude (SKILL.md)**: ì„¤ëª… ì¤‘ì‹¬
```markdown
## Stage 1: Research Setup

**Goal**: Choose project_type and define research question

**Key decision**: knowledge_repository (50%) vs systematic_review (90%)

**Read decision tree**: [skills/reference/project_type_decision_tree.md](...)
```

**Codex (AGENTS.md)**: ëª…ë ¹ ì¤‘ì‹¬
```markdown
## Task 1: Initialize Project

```bash
# Step 1: Ask user for project details
read -p "Project name: " PROJECT_NAME
read -p "Research question: " QUESTION

# Step 2: Initialize
python scholarag_cli.py init \
  --name "$PROJECT_NAME" \
  --question "$QUESTION"

# Step 3: Validate
ls projects/*/config.yaml || echo "ERROR: Initialization failed"
```
```

### ê·œì¹™ 3: Cross-Reference ëª…í™•í™”

**SKILL.mdì—ì„œ AGENTS.md ì°¸ì¡° ì‹œ**:
```markdown
## Executing Stage 5 (Automated Pipeline)

Claude will auto-execute scripts in sequence. If you're using Codex instead:

**Codex users**: See [AGENTS.md Task 5](AGENTS.md#task-5-run-stage-5-pipeline)
for bash-based workflow.
```

**AGENTS.mdì—ì„œ SKILL.md ì°¸ì¡° ì‹œ**:
```markdown
## Task 3: Configure PRISMA Criteria

**For conceptual background** on project_type thresholds:
- See [SKILL.md: Critical Branching Points](SKILL.md#critical-branching-points)
- Or [skills/reference/project_type_decision_tree.md](skills/reference/project_type_decision_tree.md)

**Executable steps**:
```bash
# Edit config.yaml
vim config.yaml
# Change line: project_type: systematic_review
```
```

---

## ğŸ”§ ì „ëµ 6: ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

### SKILL.md (Claude Agent Skills)

```markdown
---
name: scholarag
description: Build PRISMA 2020-compliant systematic literature review systems with RAG-powered analysis. Use when researcher needs automated paper retrieval (Semantic Scholar, OpenAlex, arXiv), AI-assisted PRISMA screening, vector database creation, or research conversation interface. Supports knowledge_repository (comprehensive, 50% threshold) and systematic_review (publication-quality, 90% threshold) modes.
---

# ScholaRAG: Systematic Review Automation Skill

## Quick Start (5 minutes)

**For researchers**:
1. `python scholarag_cli.py init`
2. Paste Stage 1 prompt from https://www.scholarag.com/guide/01-introduction
3. Answer Claude's questions â†’ Auto-creates project
4. Proceed through 7 stages conversationally

**For AI assistants (Claude Code)**:
- Read HTML metadata from prompts/*.md
- Follow conversation_flow patterns
- Validate using validation_rules
- Auto-execute when auto_execute: true
- Update .claude/context.json

## 7-Stage Workflow

| Stage | File to Read | Duration | Auto-Execute |
|-------|--------------|----------|--------------|
| 1 | [skills/stage1_research_setup.md](skills/stage1_research_setup.md) | 15-20 min | âœ… scholarag init |
| 2 | [skills/stage2_query_strategy.md](skills/stage2_query_strategy.md) | 15-25 min | âŒ Manual |
| 3 | [skills/stage3_prisma_config.md](skills/stage3_prisma_config.md) | 20-30 min | âŒ Manual |
| 4 | [skills/stage4_rag_design.md](skills/stage4_rag_design.md) | 10-15 min | âŒ Manual |
| 5 | [skills/stage5_execution.md](skills/stage5_execution.md) | 2-4 hours | âœ… All scripts |
| 6 | [skills/stage6_research_conversation.md](skills/stage6_research_conversation.md) | Ongoing | âŒ Interactive |
| 7 | [skills/stage7_documentation.md](skills/stage7_documentation.md) | 30-60 min | âœ… PRISMA diagram |

**Progressive disclosure**: Load stage file only when researcher enters that stage.

## Critical Branching Points

### project_type (Stage 1)
- `knowledge_repository`: 50% threshold â†’ 15K-20K papers
- `systematic_review`: 90% threshold â†’ 50-300 papers
- **Decision tree**: [skills/reference/project_type_decision_tree.md](skills/reference/project_type_decision_tree.md)

### Stage 6 Scenarios
7 research conversation modes:
- overview, hypothesis, statistics, methods, contradictions, policy, grant
- **Details**: [skills/stage6_research_conversation.md](skills/stage6_research_conversation.md)

## Error Recovery

**When errors occur**: [skills/error_recovery.md](skills/error_recovery.md)

**Quick fixes**:
- Too many papers: Refine query, re-run Stage 2
- API key missing: Add ANTHROPIC_API_KEY to .env
- Low PDF success: Filter open_access, see error_recovery.md Â§4.3

## Reference Materials

**API docs**: [skills/reference/api_reference.md](skills/reference/api_reference.md)
**Config schema**: [skills/reference/config_schema.md](skills/reference/config_schema.md)
**PRISMA checklist**: [skills/reference/prisma_guidelines.md](skills/reference/prisma_guidelines.md)
**Architecture**: https://www.scholarag.com/codebook/architecture

---

**For Codex users**: See [AGENTS.md](AGENTS.md) for bash-based task workflows.

**Token optimization**: This file ~400 lines. Stage files ~300 lines (load on-demand). Total per conversation: ~700 lines (65% reduction).
```

---

### AGENTS.md (OpenAI Codex)

```markdown
# AGENTS.md - ScholaRAG

**For**: OpenAI Codex, GPT-5-Codex autonomous agents
**Purpose**: Task-based bash workflows for ScholaRAG systematic review automation

---

## ğŸ“‹ Repository Context

**Type**: Research automation tool
**Purpose**: PRISMA 2020 systematic review + RAG-powered analysis
**Tech Stack**: Python 3.9+, ChromaDB, Claude API, Semantic Scholar API
**Main CLI**: `scholarag_cli.py`

**For conceptual overview**: See [SKILL.md](SKILL.md) (Claude-optimized)
**For architecture**: https://www.scholarag.com/codebook/architecture

---

## ğŸ¯ Task-Based Workflows

### Task 1: Initialize New Project

**When**: User says "Start new systematic review" or "Initialize ScholaRAG"

**Prerequisites Check**:
```bash
# Verify Python version
python --version | grep -E "3\.(9|10|11|12)"
# Expected: Python 3.9+ detected

# Verify git (for version control)
which git
# Expected: /usr/bin/git or similar

# Verify ScholaRAG repo
ls scholarag_cli.py
# Expected: File exists
```

**Execution**:
```bash
# Step 1: Prompt user for details
read -p "Project name (e.g., AI-Chatbots-Language-Learning): " PROJECT_NAME
read -p "Research question: " QUESTION
read -p "Domain (education/medicine/psychology/custom): " DOMAIN

# Step 2: Initialize project
python scholarag_cli.py init \
  --name "$PROJECT_NAME" \
  --question "$QUESTION" \
  --domain "$DOMAIN"

# Step 3: Validate creation
PROJECT_DIR=$(ls -td projects/* | head -1)
ls "$PROJECT_DIR/config.yaml"
# Expected: config.yaml exists

# Step 4: Check folder structure
ls "$PROJECT_DIR/data/01_identification"
ls "$PROJECT_DIR/data/02_screening"
ls "$PROJECT_DIR/rag/chroma_db"
# Expected: All folders exist
```

**Validation Checklist**:
- [ ] config.yaml created
- [ ] .scholarag metadata file exists
- [ ] data/ folders created (01_identification, 02_screening, pdfs)
- [ ] rag/chroma_db/ folder exists
- [ ] README.md generated

**Report to User**:
```
âœ… Project initialized: $PROJECT_DIR
âœ… config.yaml verified
â¡ï¸ Next Task: Design search query (Task 2)
```

---

### Task 2: Design and Test Search Query

**When**: User says "Design query" or "Stage 2"

**Conceptual Background**: See [SKILL.md: Stage 2](SKILL.md#stage-2-query-strategy)

**Execution**:
```bash
# Step 1: Navigate to project
cd "$PROJECT_DIR"

# Step 2: Show current config
grep "research_question" config.yaml

# Step 3: Help user design query
# (Interactive: Ask user for key concepts)
read -p "Main intervention term (e.g., chatbot): " INTERVENTION
read -p "Main outcome term (e.g., speaking proficiency): " OUTCOME
read -p "Population term (e.g., language learners): " POPULATION

# Step 4: Construct Boolean query
QUERY="($INTERVENTION OR \"conversational agent\") AND ($OUTCOME OR fluency) AND ($POPULATION OR EFL OR ESL)"

# Step 5: Update config.yaml
sed -i '' "s/search_query: \"\"/search_query: \"$QUERY\"/" config.yaml

# Step 6: Validate
grep "search_query" config.yaml
# Expected: search_query: "(chatbot OR ...)"
```

**Test Query** (optional):
```bash
# Preview paper count from Semantic Scholar
python scripts/01_fetch_papers.py --project . --dry-run

# Expected output:
# ğŸ” Searching Semantic Scholar (dry run)...
#    Estimated papers: ~3,245
# âœ… Paper count within optimal range (1,000-5,000)
```

**Validation Checklist**:
- [ ] search_query added to config.yaml
- [ ] Query includes intervention, outcome, population terms
- [ ] Dry run shows 1,000-5,000 papers (optimal)
- [ ] User confirms query accuracy

**Report to User**:
```
âœ… Query designed: $QUERY
âœ… Estimated papers: ~3,245
â¡ï¸ Next Task: Configure PRISMA criteria (Task 3)
```

---

### Task 3: Configure PRISMA Criteria

**When**: User says "Configure PRISMA" or "Stage 3"

**Conceptual Background**: [SKILL.md: Critical Branching Points](SKILL.md#critical-branching-points)
**Decision tree**: [skills/reference/project_type_decision_tree.md](skills/reference/project_type_decision_tree.md)

**Execution**:
```bash
# Step 1: Choose project_type
echo "Choose project type:"
echo "  1) knowledge_repository (50% threshold, comprehensive)"
echo "  2) systematic_review (90% threshold, publication-quality)"
read -p "Enter 1 or 2: " CHOICE

if [ "$CHOICE" = "1" ]; then
  PROJECT_TYPE="knowledge_repository"
elif [ "$CHOICE" = "2" ]; then
  PROJECT_TYPE="systematic_review"
else
  echo "Invalid choice"
  exit 1
fi

# Step 2: Update config.yaml
sed -i '' "s/project_type: .*/project_type: $PROJECT_TYPE/" config.yaml

# Step 3: Configure AI PRISMA rubric
cat >> config.yaml << 'EOF'

ai_prisma_rubric:
  criteria:
    - name: "Population"
      description: "University-level EFL learners"
    - name: "Intervention"
      description: "AI chatbot with speech interaction"
    - name: "Outcome"
      description: "Speaking proficiency (fluency + accuracy)"
    - name: "Study Design"
      description: "Empirical studies (RCT, quasi-experimental, pre-post)"

  decision_confidence:
    auto_include: 90  # For systematic_review
    auto_exclude: 10
    human_review_range: [85, 95]
EOF

# Step 4: Validate
python scripts/validate_config.py --project .
# Expected: âœ… config.yaml valid
```

**Validation Checklist**:
- [ ] project_type set (knowledge_repository OR systematic_review)
- [ ] ai_prisma_rubric.criteria defined (4+ criteria)
- [ ] decision_confidence thresholds set
- [ ] config.yaml passes validation

**Report to User**:
```
âœ… PRISMA configured: $PROJECT_TYPE mode
âœ… Screening threshold: 90%
â¡ï¸ Next Task: Design RAG settings (Task 4)
```

---

### Task 4: Design RAG Settings

**When**: User says "Configure RAG" or "Stage 4"

**Execution**:
```bash
# Step 1: Add RAG settings to config.yaml
cat >> config.yaml << 'EOF'

rag_settings:
  vector_db: "chromadb"
  embedding_model: "text-embedding-3-small"  # 1536 dimensions
  llm: "claude-3-5-sonnet-20241022"
  chunk_size: 1000
  chunk_overlap: 200
  retrieval_k: 10
  temperature: 0.3
EOF

# Step 2: Validate API keys
if [ -z "$ANTHROPIC_API_KEY" ]; then
  echo "âš ï¸ ANTHROPIC_API_KEY not set"
  echo "Add to .env: ANTHROPIC_API_KEY=sk-ant-api03-xxxxx"
  exit 1
fi

# Step 3: Validate config
python scripts/validate_config.py --project .
# Expected: âœ… All settings valid
```

**Validation Checklist**:
- [ ] rag_settings added to config.yaml
- [ ] ANTHROPIC_API_KEY in .env
- [ ] embedding_model valid (OpenAI model name)
- [ ] llm valid (Claude model name)

**Report to User**:
```
âœ… RAG settings configured
âœ… API keys validated
â¡ï¸ Next Task: Execute pipeline (Task 5)
â±ï¸ Estimated time: 2-4 hours (mostly automated)
```

---

### Task 5: Run Stage 5 Pipeline (Automated)

**When**: User says "Run pipeline" or "Execute all stages"

**Warning**: This task takes 2-4 hours. Run in background or tmux session.

**Execution**:
```bash
# Step 1: Fetch papers from databases
echo "ğŸ“¥ Stage 5.1: Fetching papers..."
python scripts/01_fetch_papers.py --project .
# Expected: data/01_identification/*.csv created

# Step 2: Deduplicate
echo "ğŸ”„ Stage 5.2: Deduplicating..."
python scripts/02_deduplicate.py --project .
# Expected: data/01_identification/deduplicated.csv

# Step 3: Screen papers with AI
echo "âœ… Stage 5.3: AI-assisted screening..."
python scripts/03_screen_papers.py --project .
# Expected: data/02_screening/relevant.csv

# Step 4: Download PDFs
echo "ğŸ“„ Stage 5.4: Downloading PDFs..."
python scripts/04_download_pdfs.py --project .
# Expected: data/pdfs/*.pdf (40-60% success rate typical)

# Step 5: Build RAG
echo "ğŸ—„ï¸ Stage 5.5: Building vector database..."
python scripts/05_build_rag.py --project .
# Expected: data/chroma/ populated with embeddings

# Step 6: Report statistics
echo ""
echo "ğŸ“Š Pipeline Complete! Statistics:"
echo "  Papers fetched: $(wc -l < data/01_identification/deduplicated.csv)"
echo "  Papers after screening: $(wc -l < data/02_screening/relevant.csv)"
echo "  PDFs downloaded: $(ls data/pdfs/*.pdf 2>/dev/null | wc -l)"
echo "  RAG database size: $(du -sh data/chroma/ | awk '{print $1}')"
```

**Error Handling**:
```bash
# If any script fails, capture error
if [ $? -ne 0 ]; then
  echo "âŒ Pipeline failed at step: $CURRENT_STEP"
  echo "Check logs: data/*/logs/*.txt"
  echo "For troubleshooting: See SKILL.md error_recovery.md"
  exit 1
fi
```

**Validation Checklist**:
- [ ] All 5 scripts executed successfully
- [ ] data/02_screening/relevant.csv has 50-5,000 papers
- [ ] PDFs downloaded (>30% success rate)
- [ ] data/chroma/ exists and non-empty
- [ ] No error messages in logs

**Report to User**:
```
âœ… Pipeline executed successfully!
ğŸ“Š Papers screened: XXX
ğŸ“„ PDFs downloaded: YYY
ğŸ—„ï¸ RAG database ready

â¡ï¸ Next Task: Start research conversations (Task 6)
```

---

### Task 6: Query RAG System (Interactive)

**When**: User says "Query RAG" or "Ask questions" or "Stage 6"

**Conceptual Background**: [SKILL.md: Stage 6](SKILL.md#stage-6-research-conversation)
**7 Scenarios**: [skills/stage6_research_conversation.md](skills/stage6_research_conversation.md)

**Execution**:
```bash
# Step 1: Start interactive query interface
python scripts/06_query_rag.py --project .

# User will see:
# ğŸ—„ï¸ RAG database loaded: 234 papers
# ğŸ’¬ Enter your research query (or 'exit' to quit):
#
# Available scenarios:
#   1. Context Scanning (overview)
#   2. Hypothesis Validation
#   3. Statistical Extraction
#   4. Methodology Comparison
#   5. Contradiction Detection
#   6. Policy Translation
#   7. Future Research Design
#
# Choose scenario (1-7) or enter custom query:
```

**Example Queries** (provide to user):
```
# Scenario 1: Overview
"Summarize the main themes and methodologies in my database"

# Scenario 2: Hypothesis
"My hypothesis: AI chatbots improve speaking fluency more than accuracy.
List evidence for and against."

# Scenario 3: Statistics
"Extract effect sizes (Cohen's d) from all RCT studies measuring speaking proficiency"

# Scenario 4: Methods
"Compare RCT vs quasi-experimental studies: sample sizes, interventions, outcomes"

# Scenario 5: Contradictions
"Find studies with conflicting results on chatbot effectiveness"

# Scenario 6: Policy
"Create 3 policy recommendations for implementing chatbots in university EFL programs"

# Scenario 7: Grant
"Design a follow-up study addressing gaps in current literature"
```

**Validation**: User satisfaction (qualitative)

**Report to User**:
```
ğŸ’¬ RAG system ready for queries
ğŸ“š Database: XXX papers
ğŸ¯ Choose scenario or ask custom questions

â¡ï¸ Next Task (optional): Generate documentation (Task 7)
```

---

### Task 7: Generate PRISMA Diagram

**When**: User says "Generate PRISMA" or "Create flowchart" or "Stage 7"

**Execution**:
```bash
# Step 1: Generate PRISMA flowchart
echo "ğŸ“Š Generating PRISMA 2020 flowchart..."
python scripts/07_generate_prisma.py --project .

# Expected output:
# âœ… PRISMA flowchart generated:
#    - outputs/prisma_flowchart.png
#    - outputs/prisma_flowchart.mmd (Mermaid source)

# Step 2: Open diagram (macOS)
open outputs/prisma_flowchart.png

# Step 3: Display statistics
cat outputs/prisma_statistics.txt
```

**Validation Checklist**:
- [ ] outputs/prisma_flowchart.png created
- [ ] Diagram title matches project_type (Knowledge Repository vs Systematic Review)
- [ ] Paper counts accurate at each stage
- [ ] Exclusion reasons listed

**Report to User**:
```
âœ… PRISMA diagram generated!
ğŸ“Š View at: outputs/prisma_flowchart.png
ğŸ“ˆ Statistics: outputs/prisma_statistics.txt

ğŸ‰ All 7 stages complete!
Your systematic review RAG system is ready.
```

---

## ğŸ” Validation Checklists

### Global Validation (Any Stage)

```bash
# Check project structure
ls config.yaml .scholarag README.md
ls -d data/01_identification data/02_screening data/pdfs rag/chroma_db outputs

# Check git status
git status
# Expected: No uncommitted changes (if version controlled)

# Check Python environment
python --version
pip list | grep -E "anthropic|chromadb|pandas"
```

### Per-Stage Validation

See Task X sections above for specific checklists.

---

## ğŸš¨ Error Recovery

### Common Errors

**Error 1: `config.yaml not found`**
```bash
# Solution: Re-run Task 1 (Initialize)
python scholarag_cli.py init
```

**Error 2: `ANTHROPIC_API_KEY not set`**
```bash
# Solution: Create .env file
echo "ANTHROPIC_API_KEY=sk-ant-api03-xxxxx" > .env
source .env
```

**Error 3: `Too many papers (>30,000)`**
```bash
# Solution: Refine query (Task 2)
# Edit config.yaml, add more specific terms
vim config.yaml  # Narrow search_query

# Re-run fetch
python scripts/01_fetch_papers.py --project .
```

**Error 4: `Low PDF success (<30%)`**
```bash
# Solution: Filter for open access
# Edit scripts/01_fetch_papers.py, line ~82
# Add: 'openAccessPdf': 'true'

# Re-run download
python scripts/04_download_pdfs.py --project .
```

**For detailed recovery**: [skills/error_recovery.md](skills/error_recovery.md) (Claude-optimized guide)

---

## ğŸ“Š Common Workflows

### Workflow 1: Complete 7-Stage Pipeline

```bash
# Run all tasks sequentially
python scholarag_cli.py init && \
python scripts/01_fetch_papers.py --project . && \
python scripts/02_deduplicate.py --project . && \
python scripts/03_screen_papers.py --project . && \
python scripts/04_download_pdfs.py --project . && \
python scripts/05_build_rag.py --project . && \
python scripts/06_query_rag.py --project . && \
python scripts/07_generate_prisma.py --project .
```

### Workflow 2: Rollback and Re-run Stage

```bash
# Example: Re-run Stage 3 (screening) with new threshold
rm -rf data/02_screening/*
vim config.yaml  # Change project_type
python scripts/03_screen_papers.py --project .
```

### Workflow 3: Batch Processing Multiple Projects

```bash
# Initialize 3 projects
for PROJECT in "AI-Healthcare" "AI-Education" "AI-Psychology"; do
  python scholarag_cli.py init \
    --name "$PROJECT" \
    --question "How does AI impact $PROJECT?" \
    --domain custom
done

# Process all projects
for PROJECT_DIR in projects/*; do
  python scripts/01_fetch_papers.py --project "$PROJECT_DIR"
  python scripts/02_deduplicate.py --project "$PROJECT_DIR"
  # ... continue pipeline
done
```

---

## ğŸ”— External Resources

**For Claude-optimized guides**: [SKILL.md](SKILL.md)
**For architecture**: https://www.scholarag.com/codebook/architecture
**For web documentation**: https://www.scholarag.com/guide
**For API reference**: [skills/reference/api_reference.md](skills/reference/api_reference.md)

---

**Last Updated**: 2025-10-23
**Codex Version**: Compatible with GPT-5-Codex, OpenAI Codex CLI
**ScholaRAG Version**: v1.0.8+
```

---

## ğŸ“ í´ë” ì •ë¦¬ ê¶Œì¥ ì‚¬í•­

### ì¤‘ë³µ í´ë” ì‚­ì œ

```bash
# 1. ResearcherRAG-helper 2 ì‚­ì œ (ë¶ˆí•„ìš”í•œ ì¤‘ë³µ)
rm -rf "/Volumes/External SSD/Projects/Research/ResearcherRAG-helper 2"

# 2. ì´ë¯¸ ë°±ì—…ì´ ìˆìœ¼ë¯€ë¡œ ì•ˆì „
ls -la "/Volumes/External SSD/Projects/Research/" | grep backup
# ResearcherRAG.backup (2024-10-18)
# ResearcherRAG-helper.backup (2024-10-18)
```

### ìµœì¢… êµ¬ì¡°

```
/Volumes/External SSD/Projects/Research/
â”œâ”€â”€ ScholaRAG/                    â† ë©”ì¸ ì½”ë“œ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ SKILL.md                  â† Claude Agent Skills
â”‚   â”œâ”€â”€ AGENTS.md                 â† Codex ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ CLAUDE.md                 â† Legacy redirect
â”‚   â””â”€â”€ skills/                   â† Claude ìƒì„¸ ì»¨í…ìŠ¤íŠ¸
â”‚
â”œâ”€â”€ ScholaRAG-helper/             â† ë¬¸ì„œ ì›¹ì‚¬ì´íŠ¸
â”‚   â”œâ”€â”€ AGENTS.md                 â† Codex (Next.js í”„ë¡œì íŠ¸)
â”‚   â”œâ”€â”€ CLAUDE.md                 â† Claude (ìµœì†Œ)
â”‚   â”œâ”€â”€ discussion/
â”‚   â”‚   â”œâ”€â”€ ScholaRAG_Refactoring_Plan.md
â”‚   â”‚   â””â”€â”€ Multi-Agent_Strategy_SKILL_vs_AGENTS.md
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ CLAUDE.md             â† Frontend ì „ìš©
â”‚       â””â”€â”€ AGENTS.md             â† Frontend ì „ìš©
â”‚
â”œâ”€â”€ ResearcherRAG.backup/         â† ë°±ì—… (2024-10-18)
â””â”€â”€ ResearcherRAG-helper.backup/  â† ë°±ì—… (2024-10-18)
```

---

## âœ… ì‹¤í–‰ ê³„íš

### Phase 1: íŒŒì¼ ì •ë¦¬ (ì¦‰ì‹œ)

```bash
# 1. ì¤‘ë³µ í´ë” ì‚­ì œ
rm -rf "/Volumes/External SSD/Projects/Research/ResearcherRAG-helper 2"

# 2. í™•ì¸
ls -la "/Volumes/External SSD/Projects/Research/" | grep -i researcher
# ê²°ê³¼: ScholaRAG-helper, *.backupë§Œ ì¡´ì¬ âœ…
```

### Phase 2: SKILL.md ì‘ì„± (1-2 days)

```bash
cd "/Volumes/External SSD/Projects/Research/ScholaRAG"

# 1. ê¸°ì¡´ SKILL.md ë°±ì—…
mv SKILL.md SKILL.md.codex-backup

# 2. ìƒˆ SKILL.md ì‘ì„± (ìœ„ í…œí”Œë¦¿ ì‚¬ìš©)
vim SKILL.md
# [ìœ„ "SKILL.md (Claude Agent Skills)" ì„¹ì…˜ ë‚´ìš© ë¶™ì—¬ë„£ê¸°]

# 3. AGENTS.md ì‘ì„±
vim AGENTS.md
# [ìœ„ "AGENTS.md (OpenAI Codex)" ì„¹ì…˜ ë‚´ìš© ë¶™ì—¬ë„£ê¸°]

# 4. CLAUDE.md ê°„ì†Œí™”
cat > CLAUDE.md << 'EOF'
# ScholaRAG - Legacy Context File

**âš ï¸ This file is for backward compatibility only.**

For new projects, use:
- **Claude Code**: See [SKILL.md](SKILL.md) (Agent Skills framework)
- **OpenAI Codex**: See [AGENTS.md](AGENTS.md) (Task-based workflows)

## Quick Migration

If you have an existing project using this CLAUDE.md:
1. Your project will continue to work (no breaking changes)
2. Update to SKILL.md for better token efficiency (65% reduction)
3. Read migration guide: [skills/migration_from_claude_md.md](skills/migration_from_claude_md.md)

## What Changed?

- **Before**: All context in CLAUDE.md (100 lines, loaded every conversation)
- **After**: SKILL.md (50 lines) + skills/*.md (300 lines each, loaded on-demand)
- **Benefit**: 65% token reduction, faster responses

For full refactoring plan: [ScholaRAG-helper/discussion/ScholaRAG_Refactoring_Plan.md](../ScholaRAG-helper/discussion/ScholaRAG_Refactoring_Plan.md)
EOF
```

### Phase 3: skills/ í´ë” êµ¬ì¶• (1 week)

```bash
# 1. í´ë” ìƒì„±
mkdir -p skills/scenarios skills/reference skills/example_conversations

# 2. Stageë³„ íŒŒì¼ ì‘ì„± (Phase 1 of Refactoring Plan ì°¸ì¡°)
vim skills/stage1_research_setup.md
vim skills/stage2_query_strategy.md
# ... (7 files total)

# 3. Reference ë¬¸ì„œ ì‘ì„±
vim skills/reference/project_type_decision_tree.md
vim skills/reference/api_reference.md
vim skills/reference/config_schema.md
vim skills/error_recovery.md
```

---

## ğŸ¯ ìš”ì•½

### ì§ˆë¬¸ ë‹µë³€

1. **SKILL.mdëŠ” ë‹¤ë¥¸ ì—°êµ¬ìì—ê²Œë„ í•„ìš”í•œê°€?**
   - **ì•„ë‹ˆìš”**. SKILL.mdëŠ” AI ì—ì´ì „íŠ¸(Claude/Codex)ê°€ ì½ëŠ” íŒŒì¼ì…ë‹ˆë‹¤.
   - ì—°êµ¬ìëŠ” ì›¹ì‚¬ì´íŠ¸(https://www.scholarag.com)ë¥¼ ì½ìŠµë‹ˆë‹¤.

2. **Codexì™€ Claude ëª¨ë‘ ì§€ì›í•˜ë ¤ë©´?**
   - **SKILL.md** (Claude) + **AGENTS.md** (Codex) ë³‘í–‰ ìœ ì§€
   - ë‚´ìš© ì¤‘ë³µ ìµœì†Œí™”: SSOT ì›ì¹™, cross-reference í™œìš©
   - ì—­í•  ë¶„ë¦¬: SKILL.md = ì„¤ëª… ì¤‘ì‹¬, AGENTS.md = ëª…ë ¹ ì¤‘ì‹¬

3. **ResearcherRAG-helper 2 í•„ìš”í•œê°€?**
   - **ì‚­ì œ ê¶Œì¥**
   - ë©”ì¸: ScholaRAG-helper
   - ë°±ì—…: .backup í´ë”ë¡œ ì¶©ë¶„

### í•µì‹¬ ì „ëµ

| Aspect | Claude (SKILL.md) | Codex (AGENTS.md) |
|--------|-------------------|-------------------|
| ìŠ¤íƒ€ì¼ | Conversation-first, progressive disclosure | Task-first, bash commands |
| ê¸¸ì´ | ~400 lines (ë©”ì¸) + ~300 lines/stage | ~500 lines (all tasks) |
| êµ¬ì¡° | ê³„ì¸µì  (skills/*.md ë¶„ë¦¬) | í‰ë©´ì  (í•œ íŒŒì¼ì— ëª¨ë“  task) |
| ë¡œë”© | On-demand (ë‹¨ê³„ë³„) | Upfront (ì „ì²´ ë¡œë“œ) |
| ì—ëŸ¬ ì²˜ë¦¬ | Metadata validation | Exit codes, if-else |
| ì˜ˆì‹œ | "Ask user about project_type" | `read -p "Choose 1 or 2:" CHOICE` |

### ë‹¤ìŒ ë‹¨ê³„

1. âœ… ì¤‘ë³µ í´ë” ì‚­ì œ (ì¦‰ì‹œ)
2. ğŸ“ SKILL.md ì‘ì„± (1-2 days, ìœ„ í…œí”Œë¦¿ ì‚¬ìš©)
3. ğŸ“ AGENTS.md ì‘ì„± (1-2 days, ìœ„ í…œí”Œë¦¿ ì‚¬ìš©)
4. ğŸ“ skills/ í´ë” êµ¬ì¶• (1 week, Refactoring Plan Phase 1 ì°¸ì¡°)

---

**ë¬¸ì„œ ë²„ì „**: 1.0
**ì‘ì„±ì¼**: 2025-10-23
**ì‘ì„±ì**: Claude (Anthropic) + HosungYou
